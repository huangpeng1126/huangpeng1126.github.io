<!DOCTYPE html>
<html lang="zh-CN">
    <head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
    <meta charset="UTF-8" />

    <meta name="generator" content="Hugo 0.104.3" /><meta name="theme-color" content="#fff" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    <meta name="format-detection" content="telephone=no, date=no, address=no, email=no" />
    
    <meta http-equiv="Cache-Control" content="no-transform" />
    
    <meta http-equiv="Cache-Control" content="no-siteapp" />

    <title>语音识别算法介绍 | 瞌睡鱼&amp;花脸猫 个人网站</title>

    <link rel="stylesheet" href="/css/meme.min.0bf79c6291c64b98be75f8b1a99bca305a0cc8999a7b59896522fd731aebdf7e.css"/>

    
    
        <script src="/js/meme.min.1343c21422ddd723ef2bde0b482ea241020c7d5c128b72528dd13d375565510b.js"></script>

    

    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />

        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=EB&#43;Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto&#43;Serif&#43;SC:wght@400;500;700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" media="print" onload="this.media='all'" />
        <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=EB&#43;Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto&#43;Serif&#43;SC:wght@400;500;700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" /></noscript>

    <meta name="author" content="瞌睡鱼" /><meta name="description" content="语音识别是一个具有悠久历史的研究领域，从之前传统的统计模型，到目前热度很高的E2E框……" />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#2a6df4" />
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-title" content="瞌睡鱼&amp;花脸猫 个人网站" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black" />
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="application-name" content="瞌睡鱼&amp;花脸猫 个人网站" />
    <meta name="msapplication-starturl" content="../../" />
    <meta name="msapplication-TileColor" content="#fff" />
    <meta name="msapplication-TileImage" content="../../icons/mstile-150x150.png" />
    <link rel="manifest" href="/manifest.json" />

    
    

    
    <link rel="canonical" href="https://huangpeng1126.github.io/posts/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/" />
    

<script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "datePublished": "2022-09-19T17:45:03+08:00",
        "dateModified": "2022-10-08T09:13:27+08:00",
        "url": "https://huangpeng1126.github.io/posts/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/",
        "headline": "语音识别算法介绍",
        "description": "语音识别是一个具有悠久历史的研究领域，从之前传统的统计模型，到目前热度很高的E2E框……",
        "inLanguage" : "zh-CN",
        "articleSection": "posts",
        "wordCount":  7820 ,
        "image": ["https://distill.pub/2017/ctc/assets/cost_no_skip.svg"],
        "author": {
            "@type": "Person",
            "description": "心有猛虎细嗅玫瑰",
            "email": "huangpeng1126@126.com",
            "image": "https://huangpeng1126.github.io/icons/apple-touch-icon.png",
            "url": "https://huangpeng1126.github.com/",
            "name": "瞌睡鱼"
        },
        "license": "[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)",
        "publisher": {
            "@type": "Organization",
            "name": "瞌睡鱼\u0026花脸猫 个人网站",
            "logo": {
                "@type": "ImageObject",
                "url": "https://huangpeng1126.github.io/icons/apple-touch-icon.png"
            },
            "url": "https://huangpeng1126.github.io/"
        },
        "mainEntityOfPage": {
            "@type": "WebSite",
            "@id": "https://huangpeng1126.github.io/"
        }
    }
</script>

    

<meta name="twitter:card" content="summary_large_image" />


<meta name="twitter:site" content="@reuixiy" />
<meta name="twitter:creator" content="@huangpeng1126" />

    



<meta property="og:title" content="语音识别算法介绍" />
<meta property="og:description" content="语音识别是一个具有悠久历史的研究领域，从之前传统的统计模型，到目前热度很高的E2E框……" />
<meta property="og:url" content="https://huangpeng1126.github.io/posts/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/" />
<meta property="og:site_name" content="瞌睡鱼&amp;花脸猫 个人网站" />
<meta property="og:locale" content="zh" /><meta property="og:image" content="https://distill.pub/2017/ctc/assets/cost_no_skip.svg" />
<meta property="og:type" content="article" />
    <meta property="article:published_time" content="2022-09-19T17:45:03&#43;08:00" />
    <meta property="article:modified_time" content="2022-10-08T09:13:27&#43;08:00" />
    
    <meta property="article:section" content="posts" />



    
    

    
</head>

    <body>
        <div class="container">
            
    <header class="header">
        
            <div class="header-wrapper">
                <div class="header-inner single">
                    
    <div class="site-brand">
        
            <a href="/" class="brand">瞌睡鱼&amp;花脸猫 个人网站</a>
        
    </div>

                    <nav class="nav">
    <ul class="menu" id="menu">
        
            
        
        
        
        
            
                <li class="menu-item"><a href="/posts/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon archive"><path d="M32 448c0 17.7 14.3 32 32 32h384c17.7 0 32-14.3 32-32V160H32v288zm160-212c0-6.6 5.4-12 12-12h104c6.6 0 12 5.4 12 12v8c0 6.6-5.4 12-12 12H204c-6.6 0-12-5.4-12-12v-8zM480 32H32C14.3 32 0 46.3 0 64v48c0 8.8 7.2 16 16 16h480c8.8 0 16-7.2 16-16V64c0-17.7-14.3-32-32-32z"/></svg><span class="menu-item-name">文章</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/categories/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon th"><path d="M149.333 56v80c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V56c0-13.255 10.745-24 24-24h101.333c13.255 0 24 10.745 24 24zm181.334 240v-80c0-13.255-10.745-24-24-24H205.333c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.256 0 24.001-10.745 24.001-24zm32-240v80c0 13.255 10.745 24 24 24H488c13.255 0 24-10.745 24-24V56c0-13.255-10.745-24-24-24H386.667c-13.255 0-24 10.745-24 24zm-32 80V56c0-13.255-10.745-24-24-24H205.333c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.256 0 24.001-10.745 24.001-24zm-205.334 56H24c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24zM0 376v80c0 13.255 10.745 24 24 24h101.333c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H24c-13.255 0-24 10.745-24 24zm386.667-56H488c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H386.667c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24zm0 160H488c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H386.667c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24zM181.333 376v80c0 13.255 10.745 24 24 24h101.333c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H205.333c-13.255 0-24 10.745-24 24z"/></svg><span class="menu-item-name">分类</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/tags/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" class="icon tags"><path d="M497.941 225.941L286.059 14.059A48 48 0 0 0 252.118 0H48C21.49 0 0 21.49 0 48v204.118a48 48 0 0 0 14.059 33.941l211.882 211.882c18.744 18.745 49.136 18.746 67.882 0l204.118-204.118c18.745-18.745 18.745-49.137 0-67.882zM112 160c-26.51 0-48-21.49-48-48s21.49-48 48-48 48 21.49 48 48-21.49 48-48 48zm513.941 133.823L421.823 497.941c-18.745 18.745-49.137 18.745-67.882 0l-.36-.36L527.64 323.522c16.999-16.999 26.36-39.6 26.36-63.64s-9.362-46.641-26.36-63.64L331.397 0h48.721a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882z"/></svg><span class="menu-item-name">标签</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/about/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon user-circle"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm0 96c48.6 0 88 39.4 88 88s-39.4 88-88 88-88-39.4-88-88 39.4-88 88-88zm0 344c-58.7 0-111.3-26.6-146.5-68.2 18.8-35.4 55.6-59.8 98.5-59.8 2.4 0 4.8.4 7.1 1.1 13 4.2 26.6 6.9 40.9 6.9 14.3 0 28-2.7 40.9-6.9 2.3-.7 4.7-1.1 7.1-1.1 42.9 0 79.7 24.4 98.5 59.8C359.3 421.4 306.7 448 248 448z"/></svg><span class="menu-item-name">关于</span></a>
                </li>
            
        
            
                
                    
                    
                        <li class="menu-item">
                            <a id="theme-switcher" href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-light"><path d="M193.2 104.5l48.8-97.5a18 18 0 0128 0l48.8 97.5 103.4 -34.5a18 18 0 0119.8 19.8l-34.5 103.4l97.5 48.8a18 18 0 010 28l-97.5 48.8 34.5 103.4a18 18 0 01-19.8 19.8l-103.4-34.5-48.8 97.5a18 18 0 01-28 0l-48.8-97.5l-103.4 34.5a18 18 0 01-19.8-19.8l34.5-103.4-97.5-48.8a18 18 0 010-28l97.5-48.8-34.5-103.4a18 18 0 0119.8-19.8zM256 128a128 128 0 10.01 0M256 160a96 96 0 10.01 0"/></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-dark"><path d="M27 412a256 256 0 10154-407a11.5 11.5 0 00-5 20a201.5 201.5 0 01-134 374a11.5 11.5 0 00-15 13"/></svg></a>
                        </li>
                    
                
            
        
            
                
            
        
    </ul>
</nav>

                    
                </div>
            </div>
            
    <input type="checkbox" id="nav-toggle" aria-hidden="true" />
    <label for="nav-toggle" class="nav-toggle"></label>
    <label for="nav-toggle" class="nav-curtain"></label>


        
    </header>




            
            
    <main class="main single" id="main">
    <div class="main-inner">

        

        <article class="content post h-entry" data-align="justify" data-type="posts" data-toc-num="true">

            <h1 class="post-title p-name">语音识别算法介绍</h1>

            

            
                
            

            
                

<div class="post-meta">
    
        
        <time datetime="2022-09-19T17:45:03&#43;08:00" class="post-meta-item published dt-published"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M148 288h-40c-6.6 0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h48c26.5 0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3 0 6-2.7 6-6z"/></svg>&nbsp;2022.9.19</time>
    
    
        
        <time datetime="2022-10-08T09:13:27&#43;08:00" class="post-meta-item modified dt-updated"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M400 64h-48V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H160V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H48C21.49 64 0 85.49 0 112v352c0 26.51 21.49 48 48 48h352c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm-6 400H54a6 6 0 0 1-6-6V160h352v298a6 6 0 0 1-6 6zm-52.849-200.65L198.842 404.519c-4.705 4.667-12.303 4.637-16.971-.068l-75.091-75.699c-4.667-4.705-4.637-12.303.068-16.971l22.719-22.536c4.705-4.667 12.303-4.637 16.97.069l44.104 44.461 111.072-110.181c4.705-4.667 12.303-4.637 16.971.068l22.536 22.718c4.667 4.705 4.636 12.303-.069 16.97z"/></svg>&nbsp;2022.10.8</time>
    
    
    
        
        
        
            
        
    
    
        
        <span class="post-meta-item wordcount"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;7820</span>
    
    
        
        <span class="post-meta-item reading-time"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5 0-200-89.5-200-200S145.5 56 256 56s200 89.5 200 200-89.5 200-200 200zm61.8-104.4l-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6 0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"/></svg>&nbsp;16&nbsp;分钟</span>
    
    
    
</div>

            

            <div class="post-body e-content">
                <blockquote>
<p>语音识别是一个具有悠久历史的研究领域，从之前传统的统计模型，到目前热度很高的E2E框架，不断在刷新评测指标。这篇文章仅记录这个领域的一些里程碑时间和算法。如果想深入了解ASR整个领域的发展，可以从下面三个开源框架入手，后面有时间会补上ASR整个领域的综述性质的调研</p>
<p><a href="http://kaldi-asr.org/doc/index.html" target="_blank" rel="noopener">Kaldi</a></p>
<p><a href="https://wenet.org.cn/wenet/" target="_blank" rel="noopener">WeNet</a></p>
<p><a href="https://espnet.github.io/espnet/" target="_blank" rel="noopener">ESPnet</a></p>
<p>目前ASR存在三种比较成熟的E2E方案：CTC、RNN-T、Attention，主要有两个分支：① attention类，LAS为代表的，效果比较好，但是不能满足流式；② tansducers类，这类方案天然支持流式处理。</p>
<p>模型层从原来的<code>transformer</code>到现在<code>conformer</code>成为标准方案，目前各大模型的基线变成了<code>conformer-t'ransduer</code>。</p>
<p>另外，<strong>基于传统的语音识别技术依然是业界的主流方案</strong>，特别是在定制语言模型、处理OOV、快速修复bug等方面具有巨大的优势，而这恰恰是<code>端到端语音识别</code>方案薄弱的环节。</p>
</blockquote>
<h1 id="ctc"><a href="#ctc" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>CTC</h1>
<p>CTC最开始是Graves在ICML06会议上发表的一篇论文：<a href="https://www.cs.toronto.edu/~graves/icml_2006.pdf" target="_blank" rel="noopener">Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks</a></p>
<p>，后来在他的博士论文中重新组织了公式，建立参考Graves的博士论文，因为Tensorflow中的代码实现参考的就是后面那篇博士论文（源码是“tensorflow/core/util/ctc/ctc_loss_calculator.h”），下面的介绍也是参考Graves的博士论文。</p>
<blockquote>
<p>关于CTC的介绍也大量参考率网上其它的文章：</p>
<ol>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/43534801" target="_blank" rel="noopener">一文读懂CRNN+CTC文字识别</a></p>
</li>
<li>
<p><a href="https://yudonglee.me/ctc-explained/" target="_blank" rel="noopener">CTC ALGORITHM EXPLAINED</a></p>
</li>
<li>
<p><a href="https://distill.pub/2017/ctc/" target="_blank" rel="noopener">Sequence ModelingWith CTC</a></p>
</li>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/285918756" target="_blank" rel="noopener">CTC loss 笔记+源码分享(pytorch)</a></p>
</li>
<li>
<p><a href="https://blog.csdn.net/JackyTintin/article/details/79425866" target="_blank" rel="noopener">CTC 原理及实现</a></p>
</li>
</ol>
</blockquote>
<h2 id="传统方案存在的问题"><a href="#传统方案存在的问题" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>传统方案存在的问题</h2>
<p>针对输入$x=(x_1,x_2,\dots,x_T)$，输出label seqence $y=(y_1,y_2,\dots,y_L)$，传统的方案是假设$x_i$和$y_j$之间是对齐的，即$x_i \rightarrow y_i, T=L$。但是在一些应用场景，$x_i$和$y_j$之间很难建立起这种映射关系，或者说代价很大。例如，在语音识别场景、OCR场景。<code>CTC</code>算法提出来就是为了解决这类问题。</p>
<p>下面的两个图的对比能比较直观的给出上述区别：</p>
<p><strong>图一</strong>：传统rnn只能一对一输出（当然seq2seq框架能解决这个问题）</p>
<img title="" src="https://img2020.cnblogs.com/blog/1043283/202003/1043283-20200321102037897-389680476.png" alt="" width="275" data-align="center">
<p>而CTC通过在输出词汇表中加入一个空的标记符来解决，这时词典大小编程$|V|+1$</p>
<p><strong>图二</strong>：CTC的解决方案</p>
<img title="" src="https://img2020.cnblogs.com/blog/1043283/202003/1043283-20200321102048166-614341083.png" alt="" data-align="center" width="444">
<p>从上图也可以看出，CTC方案存在缺陷，例如最后一个例子输出是<code>好棒棒</code>，显然不合理，后文会分析这个问题以及对应的解决方案。</p>
<h2 id="公式推导"><a href="#公式推导" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>公式推导</h2>
<p>在正式开始公式推导前，为了后续描述方便，预先给出一些符号定义。</p>
<ul>
<li>
<p>$L$：标签集合空间，例如英文OCR任务，空间集合是26个英文字母（假设不包含标点符号等）。$\left|L\right|$ 标签空间大小</p>
</li>
<li>
<p>$L'$：$L \cup {blank}$</p>
</li>
<li>
<p>$\mathbf S$：训练集</p>
</li>
<li>
<p>$\pi$：一条路径，描述了生成最终标签序列的一条路径，通常 $\pi \in L'^T$，具体表示了一条长度为$T$的路径（路径的具体含义可以参考下文中展开的具体描述）</p>
</li>
<li>
<p>$p(\pi | \mathbb x, \mathbf S) = \prod <em>{t=1} ^T y</em>{\pi <em>t}^t$：$y</em>{\pi_t}^t$ is the activation of output unit $\pi_t$ at time <strong>$t$</strong></p>
</li>
<li>
<p>$\mathcal{B}: L'^T \rightarrow L^{\le T}$：表示从一条路径$\pi \in L'^T$到label seqence的映射。例如： $\mathcal{B}(\text{-a-pp-plle}) = \mathcal{B}(\text{a--p-p-ll-e-})= \text{apple}$，'-'表示<code>blank</code>字符。其中映射规则是将空格移除，重复字符合并</p>
</li>
<li>
<p>$p(\mathbf l | x) = \sum_{\pi \in {\mathcal{B}^{-1}(\mathbf I)}} p(\pi | x)$，其中$\mathbf{l} \in L^{\le T}$，表示一个具体的labeling sequence</p>
</li>
<li>
<p>$\alpha_t(s)$：在<code>t</code>时刻，路径$\pi$的标签为<code>s</code>的子路径$\pi_{1:t}$概率（具体定义见下文的Forward Probability）</p>
</li>
<li>
<p>$\beta_t(s)$：在<code>t</code>时刻，路径\pi的标签为<code>s</code>的子路径$\pi_{t+1:|L'|}$概率（具体定义见下文的Backward Probability）</p>
</li>
</ul>
<h2 id="label-transition-matrix"><a href="#label-transition-matrix" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Label Transition Matrix</h2>
<blockquote>
<p>Label Transition Matrix这个名字是自己取的，感觉比较形象。</p>
</blockquote>
<p>首先举一个例子，label seqence是 <code>state</code>，首先构建$L' = \text{-s-t-a-t-e}$，构建规则是：<code>在label序列的每个token之间，以及收尾加上blank字符（这里blank字符使用'-'表示）</code></p>
<img title="CTC概率转移矩阵" src="https://pic1.zhimg.com/v2-b35c7212d02f2c4847a6038a5ef9a200_r.jpg" alt="" width="350" data-align="center">
<p>生成label sequence的过程如下：从矩阵图的左上角开始，只能往<code>右</code> 和 <code>下</code>两个方向移动，在右下角结束，每次移动一步，生成一个具体的label $s \in L$，或者一个<code>blank</code> label。左上角起始位置只能选择 <code>blank</code>或者<code>s</code>，右下角结束位置只能是 <code>e</code>或者 <code>blank</code>。上图给出了生成<code>state</code>的两条路径：$\pi_1 = \text{(--stta-tee-)},\ \pi_2=\text{sst-aaa-tee-}$，这两条路径都对应了相同的label sequence：<code>state</code>。这里的$\pi_1,\pi_2$就是上面提到的<code>路径</code>$\pi$的概念。从上图可以看到，一个具体的label seqence对应的路径数量可以枚举，但是数量太大，直接枚举计算不现实，Graves因此提出了CTC算法来解决这个问题，主要是通过动态规划算法来分而治之。其中关键的概念是<code>Forward Probability</code>和<code>Backward Probability</code></p>
<h3 id="1-forward-probability"><a href="#1-forward-probability" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>1. Forward Probability</h3>
<p>下面借用Graves Thesis的定义来阐述向前概率：</p>
<blockquote>
<p>For a labeling <strong>l</strong>, we define the <em>forward probability variables $\alpha_t(s)$</em> as the summed probability of all paths whose length <em>t</em> prefixes are mapped by $\mathcal{B}$ onto the length <em>s/2</em> prefix of <strong>l</strong>, ie:</p>
<p>$\alpha_t(s) = P(\pi_{1:t}:\mathcal{B}(\pi_{1:t})=\mathbb{l}<em>{1:s/2},\pi_t=l_s^{'}|x) = \sum\limits</em>{\substack{\pi:\ \mathcal{B}(\pi_{1:t})=\mathbb{l}<em>{1:s/2}}} \prod\limits</em>{t'=1}^t y_{\pi_{t'}}^{t'}$</p>
<p>where, for some sequence $s$, $s_{a:b}$ is the subsequence $(s_a,s_{a+1}, \dots, s_{b-1},s_b)$, and $s/2$ is rounded down to an integer value.</p>
</blockquote>
<p>简而言之，$\alpha_t(s)$是所有经过节点$s$的路径$\pi$，每条路径从开始节点到$s$节点的子节点的概率之和。给定了上面的向前概率定义，我们可以使用<code>动态规划算法</code>来计算：</p>
<p>$p(l|x) = \alpha_T(|l'|) + \alpha_T(|l'|-1)$</p>
<p>上面等式右边的第一项是路径$\pi$以<code>blank</code>结尾的概率，第二项是以序列最后一个label结尾的概率。结合<code>state</code>这个标签序列为例子，在<em>t=12</em>的时候，结尾的label只能是<code>blank</code>或者<code>e</code>这两个标签（大家可以回忆前面基于标签序列$L$构建$L'$的介绍，$|L'|=2|L|+1$）,从上面的公式可以看出我们可以递归求解上述问题：</p>
<p>$$
\begin{equation}
\begin{split}
\alpha_1(1) = y_b^1 \
\alpha_1(2) = y_{l_1}^1 \
\alpha_1(s) = 0, \forall s&gt;2
\end{split}
\end{equation}
$$</p>
<p>$$
\begin{equation}
\alpha_t(s) = y_{l'<em>s}^t \times \left{
\begin{aligned}
&amp; \alpha</em>{t-1}(s)+\alpha_{t-1}(s-1), \text{    if  } l'<em>s=b \text{ or } l'</em>{s-2}=l'<em>s \text{    ①} \
&amp; \alpha</em>{t-1}(s)+\alpha_{t-1}(s-1)+\alpha_{t-1}(s-2), \text{    otherwise,    ②} \
&amp; 0,\text{    } \forall s &lt; |l'|-2|T-t|-1， \text{    ③}
\end{aligned}
\right.</p>
<p>\end{equation}
$$</p>
<p>对于公式(2)里三种情况：</p>
<ol>
<li>
<p>这种情况参考下图。如果当前时刻<code>t</code>的标签$s=\epsilon \text{,  or  } l'<em>s = l'</em>{s-2}$，那么在<code>t-1</code>时刻<code>s</code>可能的取值为$s \in {s, s-1}$ （这里需要仔细琢磨一下，需要确保加入<code>t</code>时间的标签后<strong>多条路径的概率计算保持相等</strong>）</p>
<img src="https://distill.pub/2017/ctc/assets/cost_no_skip.svg" title="" alt="" data-align="center">
</li>
<li>
<p>参考下图，当前时刻<code>t</code>的标签为非空标签，那么前一个标签必然为空，前两个标签为有效并且与当前标签不等的标签，因此有三条路径</p>
<img title="" src="https://distill.pub/2017/ctc/assets/cost_regular.svg" alt="" data-align="center">
</li>
<li>
<p>其它路径都是非法的，因为剩余标签没有足够的<code>time steps</code>来输入</p>
</li>
</ol>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="c1">// tensorflow示例代码(tensorflow/core/util/ctc/ctc_loss_calculator.h)
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">TT</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="n">CTCLossCalculator</span><span class="o">&lt;</span><span class="n">TT</span><span class="o">&gt;::</span><span class="n">CalculateForwardVariables</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">l_prime</span><span class="p">,</span> <span class="k">const</span> <span class="n">Matrix</span><span class="o">&amp;</span> <span class="n">y</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ctc_merge_repeated</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">Matrix</span><span class="o">*</span> <span class="n">log_alpha</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="k">using</span> <span class="n">Eigen</span><span class="o">::</span><span class="n">numext</span><span class="o">::</span><span class="n">log</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1">// Number of cols is the number of time steps = number of cols in target
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// after the output delay.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// U: 转移矩阵的序列长度，即加入空白字符的标签序列长度
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// T: 输入x的长度
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// log_alpha shape: (U, T)
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">log_alpha</span><span class="o">-&gt;</span><span class="n">setConstant</span><span class="p">(</span><span class="n">kLogZero</span><span class="o">&lt;</span><span class="n">TT</span><span class="o">&gt;</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="kt">int</span> <span class="n">U</span> <span class="o">=</span> <span class="n">l_prime</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">  <span class="kt">int</span> <span class="n">T</span> <span class="o">=</span> <span class="n">log_alpha</span><span class="o">-&gt;</span><span class="n">cols</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">CHECK_EQ</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">log_alpha</span><span class="o">-&gt;</span><span class="n">rows</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1">// Initial alpha values in (GravesTh) Eq 7.5 and Eq 7.6.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// 参看上面的公式 (1)，初始化，注意这里的t和s起始索引从 0 开始，公式里从 1 开始
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// (0, 0) 第一个 0 表示 s 值，第二个 0 表示 t 
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">log_alpha</span><span class="o">-&gt;</span><span class="n">coeffRef</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">(</span><span class="n">blank_index_</span><span class="p">,</span> <span class="n">output_delay_</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">  <span class="c1">// Below, l_prime[1] == labels[0]
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">auto</span> <span class="n">label_0</span> <span class="o">=</span> <span class="p">(</span><span class="n">l_prime</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">?</span> <span class="n">l_prime</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">:</span> <span class="n">blank_index_</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="n">log_alpha</span><span class="o">-&gt;</span><span class="n">coeffRef</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">(</span><span class="n">label_0</span><span class="p">,</span> <span class="n">output_delay_</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">t</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">;</span> <span class="o">++</span><span class="n">t</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// If there is not enough time to output the remaining labels or
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">// some labels have been skipped, then let log_alpha(u, t) continue to
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">// be kLogZero.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">u</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">U</span> <span class="o">-</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">T</span> <span class="o">-</span> <span class="n">t</span><span class="p">)));</span> <span class="n">u</span> <span class="o">&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">min</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">         <span class="o">++</span><span class="n">u</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="c1">// Begin (GravesTh) Eq 7.9
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="c1">// Add in the u, t - 1 term.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="k">auto</span> <span class="n">sum_log_alpha</span> <span class="o">=</span> <span class="n">kLogZero</span><span class="o">&lt;</span><span class="n">TT</span><span class="o">&gt;</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="p">(</span><span class="n">ctc_merge_repeated</span> <span class="o">||</span> <span class="n">l_prime</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">==</span> <span class="n">blank_index_</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">sum_log_alpha</span> <span class="o">=</span> <span class="n">log_alpha</span><span class="o">-&gt;</span><span class="n">coeff</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">      <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="c1">// Add in the u - 1, t - 1 term.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="k">if</span> <span class="p">(</span><span class="n">u</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">sum_log_alpha</span> <span class="o">=</span>
</span></span><span class="line"><span class="cl">            <span class="n">LogSumExp</span><span class="p">(</span><span class="n">sum_log_alpha</span><span class="p">,</span> <span class="n">log_alpha</span><span class="o">-&gt;</span><span class="n">coeff</span><span class="p">(</span><span class="n">u</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">      <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="c1">// Add in the u - 2, t - 1 term if l_prime(u) != blank or l_prime(u-2).
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="k">if</span> <span class="p">(</span><span class="n">u</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">const</span> <span class="kt">bool</span> <span class="n">matching_labels_merge</span> <span class="o">=</span>
</span></span><span class="line"><span class="cl">            <span class="n">ctc_merge_repeated</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">l_prime</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">==</span> <span class="n">l_prime</span><span class="p">[</span><span class="n">u</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">l_prime</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">!=</span> <span class="n">blank_index_</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">matching_labels_merge</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">          <span class="n">sum_log_alpha</span> <span class="o">=</span>
</span></span><span class="line"><span class="cl">              <span class="n">LogSumExp</span><span class="p">(</span><span class="n">sum_log_alpha</span><span class="p">,</span> <span class="n">log_alpha</span><span class="o">-&gt;</span><span class="n">coeff</span><span class="p">(</span><span class="n">u</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">      <span class="p">}</span>
</span></span><span class="line"><span class="cl">      <span class="c1">// Multiply the summed alphas with the activation log probability.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="n">log_alpha</span><span class="o">-&gt;</span><span class="n">coeffRef</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="o">=</span>
</span></span><span class="line"><span class="cl">          <span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">(</span><span class="n">l_prime</span><span class="p">[</span><span class="n">u</span><span class="p">],</span> <span class="n">output_delay_</span> <span class="o">+</span> <span class="n">t</span><span class="p">))</span> <span class="o">+</span> <span class="n">sum_log_alpha</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>  <span class="c1">// End (GravesTh) Eq 7.9.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><h3 id="2-backward-probability"><a href="#2-backward-probability" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>2. Backward Probability</h3>
<p>后向概率计算与前向概率计算类似，不展开描述，直接给出公式（参考Graves的博士论文），下面先给出后向概率的定义：</p>
<blockquote>
<p>The <em>backword probability variables</em> $\beta_t(s)$ are defined as the summed probability of all paths whose suffixes starting at $t+1$ map onto the suffix of <em><strong>l</strong></em> starting at label $s/2$.  $\beta_t(s) = P(\pi_{t+1:T}:\mathcal{B}(\pi_{t+1:T})=\mathbb{l}<em>{s/2:|\mathbb{l}|},\pi_t=l_s^{'}|x) = \sum\limits</em>{\substack{\pi:\ \mathcal{B}(\pi_{t+:T})=|\mathbb{l}|<em>{s/2:\mathbb{l}}}} \prod\limits</em>{t'=t+1}^T y_{\pi_{t'}}^{t'}$</p>
</blockquote>
<p>$$
\begin{equation}
\begin{split}
\beta_T(|\mathbb{l}'|) = 1\
\beta_T(|\mathbb{l}'-1|) = 1\
\beta_T(s) = 0, \forall s &lt; |\mathbb{l}'|-1
\end{split}
\end{equation}
$$</p>
<p>$$
\begin{equation}
\beta_t(s) = y_{l'<em>s}^t \times \left{
\begin{aligned}
&amp; \beta</em>{t+1}(s)+\alpha_{t+1}(s+1), \text{    if  } l'<em>s=b \text{ or } l'</em>{s+2}=l'<em>s \text{    ①} \
&amp; \beta</em>{t+1}(s)+\alpha_{t+1}(s+1)+\alpha_{t+1}(s+2), \text{    otherwise,    ②} \
&amp; 0,\text{    } \forall s &gt; 2t \text{ or } s&gt;|\mathbb{l'}|， \text{    ③}
\end{aligned}
\right.</p>
<p>\end{equation}
$$</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">template</span> <span class="o">&lt;</span><span class="k">class</span> <span class="nc">TT</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="n">CTCLossCalculator</span><span class="o">&lt;</span><span class="n">TT</span><span class="o">&gt;::</span><span class="n">CalculateBackwardVariables</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">l_prime</span><span class="p">,</span> <span class="k">const</span> <span class="n">Matrix</span><span class="o">&amp;</span> <span class="n">y</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ctc_merge_repeated</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">Matrix</span><span class="o">*</span> <span class="n">log_beta</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="c1">// Number of cols is the number of time steps =  number of cols in target.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// Matrix log_beta =
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">//    Matrix::Constant(l_prime.size(), y.cols() - output_delay_,
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// kLogZero);
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">using</span> <span class="n">Eigen</span><span class="o">::</span><span class="n">numext</span><span class="o">::</span><span class="n">log</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">log_beta</span><span class="o">-&gt;</span><span class="n">setConstant</span><span class="p">(</span><span class="n">kLogZero</span><span class="o">&lt;</span><span class="n">TT</span><span class="o">&gt;</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">  <span class="kt">int</span> <span class="n">T</span> <span class="o">=</span> <span class="n">log_beta</span><span class="o">-&gt;</span><span class="n">cols</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">  <span class="kt">int</span> <span class="n">U</span> <span class="o">=</span> <span class="n">l_prime</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">  <span class="n">CHECK_EQ</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">log_beta</span><span class="o">-&gt;</span><span class="n">rows</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1">// Initial beta values in (GravesTh) Eq 7.13: log of probability 1.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">u</span> <span class="o">=</span> <span class="n">U</span> <span class="o">-</span> <span class="mi">2</span><span class="p">;</span> <span class="n">u</span> <span class="o">&lt;</span> <span class="n">U</span><span class="p">;</span> <span class="o">++</span><span class="n">u</span><span class="p">)</span> <span class="n">log_beta</span><span class="o">-&gt;</span><span class="n">coeffRef</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">T</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">t</span> <span class="o">=</span> <span class="n">T</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span> <span class="n">t</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">;</span> <span class="o">--</span><span class="n">t</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// If there is not enough time to output the remaining labels or
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">// some labels have been skipped, then let log_beta(u, t) continue to
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">// be kLogZero.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">u</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">U</span> <span class="o">-</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">T</span> <span class="o">-</span> <span class="n">t</span><span class="p">)));</span> <span class="n">u</span> <span class="o">&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">min</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">         <span class="o">++</span><span class="n">u</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="c1">// Begin (GravesTh) Eq 7.15
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="c1">// Add in the u, t + 1 term.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="k">if</span> <span class="p">(</span><span class="n">ctc_merge_repeated</span> <span class="o">||</span> <span class="n">l_prime</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">==</span> <span class="n">blank_index_</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">log_beta</span><span class="o">-&gt;</span><span class="n">coeffRef</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="o">=</span>
</span></span><span class="line"><span class="cl">            <span class="n">LogSumExp</span><span class="p">(</span><span class="n">log_beta</span><span class="o">-&gt;</span><span class="n">coeff</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                      <span class="n">log_beta</span><span class="o">-&gt;</span><span class="n">coeff</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">                          <span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">(</span><span class="n">l_prime</span><span class="p">[</span><span class="n">u</span><span class="p">],</span> <span class="n">output_delay_</span> <span class="o">+</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)));</span>
</span></span><span class="line"><span class="cl">      <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="c1">// Add in the u + 1, t + 1 term.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="k">if</span> <span class="p">(</span><span class="n">u</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&lt;</span> <span class="n">U</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">log_beta</span><span class="o">-&gt;</span><span class="n">coeffRef</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="o">=</span>
</span></span><span class="line"><span class="cl">            <span class="n">LogSumExp</span><span class="p">(</span><span class="n">log_beta</span><span class="o">-&gt;</span><span class="n">coeff</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                      <span class="n">log_beta</span><span class="o">-&gt;</span><span class="n">coeff</span><span class="p">(</span><span class="n">u</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">                          <span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">(</span><span class="n">l_prime</span><span class="p">[</span><span class="n">u</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">output_delay_</span> <span class="o">+</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)));</span>
</span></span><span class="line"><span class="cl">      <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="c1">// Add in the u + 2, t + 1 term if l_prime(u) != blank or l_prime(u+2).
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="k">if</span> <span class="p">(</span><span class="n">u</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">&lt;</span> <span class="n">U</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">const</span> <span class="kt">bool</span> <span class="n">matching_labels_merge</span> <span class="o">=</span>
</span></span><span class="line"><span class="cl">            <span class="n">ctc_merge_repeated</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">l_prime</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">==</span> <span class="n">l_prime</span><span class="p">[</span><span class="n">u</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">l_prime</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">!=</span> <span class="n">blank_index_</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">matching_labels_merge</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">          <span class="c1">// Add in u + 2 term.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>          <span class="n">log_beta</span><span class="o">-&gt;</span><span class="n">coeffRef</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="o">=</span>
</span></span><span class="line"><span class="cl">              <span class="n">LogSumExp</span><span class="p">(</span><span class="n">log_beta</span><span class="o">-&gt;</span><span class="n">coeff</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                        <span class="n">log_beta</span><span class="o">-&gt;</span><span class="n">coeff</span><span class="p">(</span><span class="n">u</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">                            <span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">(</span><span class="n">l_prime</span><span class="p">[</span><span class="n">u</span> <span class="o">+</span> <span class="mi">2</span><span class="p">],</span> <span class="n">output_delay_</span> <span class="o">+</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)));</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">      <span class="p">}</span>  <span class="c1">// End (GravesTh) Eq. 7.15
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><h3 id="loss计算"><a href="#loss计算" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Loss计算</h3>
<p>优化目标是最大化标签序列的概率似然函数，损失函数则是简单的概率似然函数的负数：</p>
<p>$$
\begin{equation}
\mathcal{O} = -ln\left(
\prod\limits_{(x,z) \in \mathcal{S}} p(z|x) \right)
= -\sum\limits_{(x,z) \in \mathcal{S}} ln p(z|x)
\end{equation}
$$</p>
<p>要求出公式(5)的偏导数，首先要计算标签$z$的概率 $p(z|x)$ （这里的符号$z$表示的是实际输出的标签序列）</p>
<p>首先，我们可以根据$\alpha_t(s)\text{和}\beta_t(s)\text{的定义得到}\alpha_t(s)\beta_t(s)$：</p>
<p>$$
\begin{equation}
\alpha_t(s) \beta_t(s)
= \sum\limits_{\substack{\pi \in \mathcal{B}^{-1}(z)\
\pi_t=z'<em>s}} \prod\limits</em>{t=1}^T y_{\pi_t}^t
= \sum\limits_{\substack{\pi \in \mathcal{B}^{-1}(z)\
\pi_t=z'_s}} p(\pi|x)
\end{equation}
$$</p>
<p>公式(6)其实就是一条经过标签节点<code>s</code>的概率，使用$z'$代表路径$pi$，$z$表示目标标签序列：</p>
<p>$$
\begin{equation}
p(z|x) = \sum\limits_{s=1}^{|z'|} \alpha_t(s) \beta_t(s)
\end{equation}
$$</p>
<p>上面公式中的<code>t</code>实际上是一个常量，在TensorFlow的源码中选取$t=0$来计算：</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">template</span> <span class="o">&lt;</span><span class="k">class</span> <span class="nc">T</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">VectorIn</span><span class="p">,</span> <span class="k">typename</span> <span class="n">VectorOut</span><span class="p">,</span> <span class="k">typename</span> <span class="n">MatrixIn</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">          <span class="k">typename</span> <span class="n">MatrixOut</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="n">Status</span> <span class="n">CTCLossCalculator</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;::</span><span class="n">CalculateLoss</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="n">VectorIn</span><span class="o">&amp;</span> <span class="n">seq_len</span><span class="p">,</span> <span class="k">const</span> <span class="n">LabelSequences</span><span class="o">&amp;</span> <span class="n">labels</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">MatrixIn</span><span class="o">&gt;&amp;</span> <span class="n">inputs</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">preprocess_collapse_repeated</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="kt">bool</span> <span class="n">ctc_merge_repeated</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">ignore_longer_outputs_than_inputs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">VectorOut</span><span class="o">*</span> <span class="n">loss</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">MatrixOut</span><span class="o">&gt;*</span> <span class="n">gradients</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">DeviceBase</span><span class="o">::</span><span class="n">CpuWorkerThreads</span><span class="o">*</span> <span class="n">workers</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     <span class="p">......</span>
</span></span><span class="line"><span class="cl"> <span class="c1">// The loss is computed as the log(p(z|x)) between the target and
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="c1">// prediction. Do lazy evaluation of log_prob here.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="n">T</span> <span class="n">log_p_z_x</span> <span class="o">=</span> <span class="n">kLogZero</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">      <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">u</span> <span class="o">&lt;</span> <span class="n">l_prime</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">u</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="c1">// (GravesTh) Eq 7.26, sum over all paths for t = 0.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">log_p_z_x</span> <span class="o">=</span> <span class="n">LogSumExp</span><span class="p">(</span><span class="n">log_p_z_x</span><span class="p">,</span> <span class="n">log_alpha_b</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">log_beta_b</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="mi">0</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">      <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="p">(</span><span class="o">*</span><span class="n">loss</span><span class="p">)(</span><span class="n">b</span><span class="p">)</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_p_z_x</span><span class="p">;</span>  <span class="c1">// Use negative log loss for display.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">......</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><h2 id="gradient"><a href="#gradient" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Gradient</h2>
<p>梯度计算可以应用链式法则来计算，先回顾和定义我们将使用到的一些符号：</p>
<blockquote>
<p>$$
\begin{aligned}
&amp; y_k^t: \text{在t时刻标签为k的概率，这个数值一般是softmax网络层的输出, } (y_0^t, y_1^t, \dots, y_k^t, \dots, y_C^t)\
&amp; lab(z,k) = {s : z'_s = k} \text{：出现在z'序列中标签为k的s下标集合}
\end{aligned}
$$</p>
</blockquote>
<p>$$
\begin{equation}
\frac{\partial \alpha_t(s) \beta_t(s)}{\partial y_k^t} = \left{
\begin{aligned}
&amp;\frac{\alpha_t(s) \beta_t(s)} {y_k^t} \text{, if k occurts in z'} \<br>
&amp;0 \text{, otherwise}
\end{aligned}
\right.</p>
<p>\end{equation}
$$</p>
<p>结合公式(7)和公式(8)，得到$p(z|x)$的导数如下：</p>
<p>$$
\begin{equation}
\frac{\partial p(z|x)}{\partial y_k^t}
= \frac{1}{y_k^t} \sum\limits_{s \in lab(z,k)} \alpha_t(s) \beta_t(s)
\end{equation}
$$</p>
<p>结合公式(5)和(8)：</p>
<p>$$
\frac{\partial O} {\partial y_k^t}
= - \frac{1}{p(z|x) y_k^t} \sum\limits_{s \in lab(z,k)} \alpha_t(s) \beta_t(s)
$$</p>
<p>输入到CTC的输入层是经过softmax后的概率分布，假设在最后一层的输入是$u_k^t=(u_0^t,u_1^t, \dots, u_C^t)$，我们需要计算$\frac{\partial y_{k'}^t}{\partial u_k^t}$:</p>
<p>$$
\frac{\partial y_{k'}^t}{\partial u_k^t}
= y_{k'}^t \delta_{kk'} - y_{k'}^t y_k^t,\ \delta_{kk'}=1 \text{ if }k=k'
, \text{  else } \delta_{kk'}=0
$$</p>
<p>最终的梯度公式如下：</p>
<p>$$
\begin{equation}
\begin{aligned}
\frac{\partial O} {\partial u_k^t}
&amp;= - \sum\limits_{k'} \frac{\partial O}{\partial y_{k'}^t}
\frac{\partial y_{k'}^t}{\partial u_k^t} \
&amp;= y_k^t - \frac{1}{p(z|x)} \sum\limits_{s \in lab(z,k)} \alpha_t(s) \beta_t(s) \text{，    ?最后一步没推导出来！}</p>
<p>\end{aligned}
\end{equation}
$$</p>
<p><strong>梯度的公式推导最后部分没大看懂，待后续研读之后再补充这部分</strong></p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="c1">// Using (GravesTh) Eq 7.26 &amp; 7.34.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">TT</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="n">CTCLossCalculator</span><span class="o">&lt;</span><span class="n">TT</span><span class="o">&gt;::</span><span class="n">CalculateGradient</span><span class="p">(</span><span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">l_prime</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                              <span class="k">const</span> <span class="n">Matrix</span><span class="o">&amp;</span> <span class="n">y</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                              <span class="k">const</span> <span class="n">Matrix</span><span class="o">&amp;</span> <span class="n">log_alpha</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                              <span class="k">const</span> <span class="n">Matrix</span><span class="o">&amp;</span> <span class="n">log_beta</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                              <span class="n">TT</span> <span class="n">log_p_z_x</span><span class="p">,</span> <span class="n">Matrix</span><span class="o">*</span> <span class="n">dy</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="c1">// Only working with the leftmost part of dy for this batch element.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">auto</span> <span class="n">dy_b</span> <span class="o">=</span> <span class="n">dy</span><span class="o">-&gt;</span><span class="n">leftCols</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">cols</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1">// It is possible that no valid path is found if the activations for the
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// targets are zero.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">if</span> <span class="p">(</span><span class="n">log_p_z_x</span> <span class="o">==</span> <span class="n">kLogZero</span><span class="o">&lt;</span><span class="n">TT</span><span class="o">&gt;</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">LOG</span><span class="p">(</span><span class="n">WARNING</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;No valid path found.&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">dy_b</span> <span class="o">=</span> <span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="kt">int</span> <span class="n">L</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">rows</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">  <span class="kt">int</span> <span class="n">T</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">cols</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">  <span class="kt">int</span> <span class="n">U</span> <span class="o">=</span> <span class="n">l_prime</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">t</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span> <span class="o">-</span> <span class="n">output_delay_</span><span class="p">;</span> <span class="o">++</span><span class="n">t</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">Array</span> <span class="nf">prob_sum</span><span class="p">(</span><span class="n">L</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">prob_sum</span><span class="p">.</span><span class="n">setConstant</span><span class="p">(</span><span class="n">kLogZero</span><span class="o">&lt;</span><span class="n">TT</span><span class="o">&gt;</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">u</span> <span class="o">&lt;</span> <span class="n">U</span><span class="p">;</span> <span class="o">++</span><span class="n">u</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="kt">int</span> <span class="n">l</span> <span class="o">=</span> <span class="n">l_prime</span><span class="p">[</span><span class="n">u</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">      <span class="n">prob_sum</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">LogSumExp</span><span class="p">(</span><span class="n">prob_sum</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">log_alpha</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="o">+</span> <span class="n">log_beta</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">t</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">l</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">l</span> <span class="o">&lt;</span> <span class="n">L</span><span class="p">;</span> <span class="o">++</span><span class="n">l</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="c1">// Negative term in (GravesTh) Eq 7.28.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="k">auto</span> <span class="n">negative_term</span> <span class="o">=</span> <span class="n">expf</span><span class="p">(</span><span class="n">prob_sum</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">-</span> <span class="n">log_p_z_x</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="n">dy_b</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">output_delay_</span> <span class="o">+</span> <span class="n">t</span><span class="p">)</span> <span class="o">=</span> <span class="n">y</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">output_delay_</span> <span class="o">+</span> <span class="n">t</span><span class="p">)</span> <span class="o">-</span> <span class="n">negative_term</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table></div>
</div>
</div><h2 id="ctc方案的缺陷"><a href="#ctc方案的缺陷" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>CTC方案的缺陷</h2>
<p>这里引用知乎上的一个图片来介绍会让大家有更加直观的理解：</p>
<img title="" src="https://pic3.zhimg.com/80/v2-2bf4f9babeefff499d61b210f2c394f6_1440w.jpg" alt="" data-align="center" width="450">
<p>CTC存在的问题：</p>
<ol>
<li>
<p>每一次输出结果都是独立的</p>
</li>
<li>
<p>可能会出现重复输出的问题</p>
</li>
</ol>
<p>其中第二个问题的深层次原因还是由于问题一引起的。上图是一个例子，假设前面三帧输入对应的输出是三个连续的<code>ccc</code>，按照CTC的映射函数$\mathcal{B}$连续字符的输出是一个<code>c</code>，但是由于中间的识别问题输出了一个非空字符$\mathit {\Phi}$，导致输出为<code>cc</code>。</p>
<h1 id="rnn-t--rnn-transducer"><a href="#rnn-t--rnn-transducer" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Rnn-T ( Rnn Transducer)</h1>
<p><a href="https://arxiv.org/abs/1211.3711" target="_blank" rel="noopener">RNN-T</a> 文章是Graves 2012年提出来的，主要是针对CTC的独立性假设缺陷的改进方案。</p>
<p>下面先给出文章里的一些符号定义：</p>
<blockquote>
<p>$x=(x_1,x_2,\dots,x_T) \in \mathcal{X^*}$：输入序列</p>
<p>$y=(y_1,y_2,\dots,y_U) \in \mathcal{Y^*}$：输出序列</p>
<p>$\tilde {\mathcal{Y}} = \mathcal{Y} \cup \mathit{\Phi}$：扩展输出空间</p>
<p>$\alpha$：定义一个<code>对齐</code>的路径，通过映射函数$\mathcal{B}$可以映射到一个真实的$y$序列，例如$\alpha=(y_1,\mathit{\Phi},\mathit{\Phi},y_2,\mathit{\Phi},y_3)$经过$\mathcal{B}(\alpha)$映射等于$y=(y_1,y_2,y_3)$</p>
<p>$\mathcal{B}$：映射函数，实现$\tilde{\mathcal{Y}^<em>} \rightarrow \mathcal{Y}^</em>$的映射</p>
</blockquote>
<p>模型整体目标函数：</p>
<p>$$
\begin{equation}
P(y \in \mathcal{Y}^*|x) = \sum\limits_{\alpha \in \mathcal{B}^{-1}} P(\alpha|x)
\end{equation}
$$</p>
<p>整体模型框架如下图：</p>
<img title="" src="https://pic3.zhimg.com/80/v2-9759d77c7ff27722d151d52e439bda4a_1440w.jpg" alt="" data-align="center" width="289">
<p>RNN-T模型引入了<code>TranscriptionNet</code>也就是图中的<code>Encoder</code>（可以使用任何声学模型的结构），相当于声学模型部分，图中的<code>PredictionNet</code>实际上相当于语言模型（可以使用单向的循环神经网络来构建）。模型中比较新奇，同时也是最重要的结构就是联合网络<code>Joint Net</code>，一般可以使用前向网络来进行建模。联合网络的作用就是将语言模型和声学模型的状态通过某种思路结合在一起，可以是拼接操作，也可以是直接相加等，考虑到语言模型和声学模型可能有不同的权重问题，似乎拼接操作更加合理一些。但是论文中使用的是加法操作。</p>
<h2 id="transcription-network-mathcalf"><a href="#transcription-network-mathcalf" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Transcription Network $\mathcal{F}$</h2>
<p>转录网络$\mathcal{F}$就是图中的<code>Encoder</code>，将输入$x$转换成向量$f=(f_1,f_2,\dots,f_T)$，</p>
<p>$$
\begin{equation}
\begin{aligned}
&amp;\overleftarrow{h_t} = \mathcal{H}\left(
W_{i\overleftarrow{h}} i_t
+ W_{\overleftarrow{h}\overleftarrow{h}} \overleftarrow{h}<em>{t+1}
+ b</em>{\overleftarrow{h}}
\right)\</p>
<p>&amp;\overrightarrow{h_t} = \mathcal{H}\left(
W_{i\overrightarrow{h}} i_t
+ W_{\overrightarrow{h}\overrightarrow{h}} \overrightarrow{h}<em>{t-1}
+ b</em>{\overrightarrow{h}}
\right)\
&amp;o_t = W_{\overrightarrow{h}o} \overrightarrow{h}<em>t
+ W</em>{\overleftarrow{h}o} \overleftarrow{h}_t + b_o
\end{aligned}
\end{equation}
$$</p>
<p>最终转录网络的输出为$f_t$，是一个$K+1$向量（$K$是输出标签空间大小）</p>
<h2 id="prediction-netowrk-mathcalg"><a href="#prediction-netowrk-mathcalg" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Prediction Netowrk $\mathcal{G}$</h2>
<p>预测网络$\mathcal{G}$将目标向量$\hat{y}=(\Phi,y_1,y_2,\dots,y_U)$转换成向量$g=(g_0,g_1,\dots,g_U)$，类似于语言模型作用（注意，这里的长度是$U+1$）,RNN网络使用的是LSTM</p>
<p>$$
\begin{equation}
\begin{aligned}
&amp;h_u = \mathcal{H}(W_{ih} \hat{y_u} + W_{hh} h_{u-1} + b_h)\
&amp;g_u = W_{ho} h_u + b_o
\end{aligned}
\end{equation}
$$</p>
<p>针对序列输入中某一时刻<code>t</code>的输入 $y_t$，是一个$K$维的<code>onehot</code>向量，例如如果$y_t=k$，那么$k^{th}$位置为1，其余都为0。而$\mathit{\Phi}$是全为0的$K$维向量。输出层为$K+1$维向量（多出的一个维度是扩展的$\Phi$）。也就是说，输出的$g_u$也是$K+1$维向量。</p>
<h2 id="joint-network"><a href="#joint-network" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Joint Network</h2>
<p>联合网络将$\mathcal{G}$和$\mathcal{F}$合并之后输出一个概率密度函数（类似于softmax）。给定转录输出向量$f_t, 1\le t \le T$，预测网络输出向量$g_u, 0 \le u \le U$，标签$k \in \tilde{Y}$，概率密度函数为：</p>
<p>$$
\begin{equation}
h(k,t,u) = exp(f_t^k + g_u^k)
\end{equation}
$$</p>
<p>其中$k$表示向量的第 $k^{th}$元素，归一化后的密度函数为：</p>
<p>$$
\begin{equation}</p>
<p>P(k \in \tilde{Y} | t,u) = \frac{h(k,t,u)}{\sum_{k' \in \tilde{Y}} h(k',t,u)}
\end{equation}
$$</p>
<p>可以看到RNN-T通过Prediction Network $\mathcal{G}$和JoinNet引入了Token之间的相关性，下面给一个图简单介绍一下它整体的优化目标计算逻辑，和CTC有些类似，也引入了<code>forward &amp; backward variable</code>。</p>
<p>为了解析路径概率，RNN-T使用了一张概率转移图，如下所示：</p>
<img title="" src="http://bat.sjtu.edu.cn/wp-content/uploads/2019/03/word-image-13.png" alt="" data-align="center" width="288">
<p>概率转移矩阵中的横坐标<code>t</code>表示声学输入编码后的状态$f_t$，纵坐标表示预测标签编码后的$g_u$。在介绍如何利用图示的概率转移矩阵计算路径概率前先引入以下公式定义：</p>
<p>$$
\begin{equation}
\begin{aligned}
\alpha(t,u) &amp;= \alpha(t-1,u)\mathit{\Phi}(t-1,u) \
&amp;+ \alpha(t,u-1)y(t,u-1) \
\beta(t,u)  &amp;= \beta(t+1,u)\mathit{\Phi}(t,u) \
&amp;+ \beta(t,u+1)y(t,u) \
\alpha(0,1) &amp;=1 \
\beta(T,U) &amp;= \mathit{\Phi}(T,U) \
P(y|x) &amp;= \alpha(T,U) \mathit{\Phi}(T,U)
\end{aligned}
\end{equation}
$$</p>
<p>首先，$\alpha(t,u)$定义了向前变量，含义是<code>读取前t个输入</code>$f_{[1:t]}$<code>输出是</code>$y_{[1:u]}$的概率。同理，$\beta(t,u)$定义了向后变量，含义是<code>读取从t+1开始到最后一个输入为止的编码后输入特征</code>$f_{[t+1:T]}$，输出概率是$y_{[u+1:U]}$。</p>
<ul>
<li>
<p>在概率转移矩阵中，<code>(t,u)</code>节点表示在输入前<code>t</code>个，输出前<code>u</code>个元素的概率。</p>
</li>
<li>
<p>横坐标方向移动（横移）表示输出空间点概率，即 $\mathit{\Phi}(t,u)$，意味着在$(t,u)$为止输出为空；纵坐标方向移动（纵向）表示输出纵坐标对应标签的概率，即 $y(t,u)$是输出$y的(u+1)^{th}$标签的概率。</p>
</li>
<li>
<p>完成解析路径从左下角开始，在右上角结束。底部黑色节点表示在空节点</p>
</li>
</ul>
<p>从上图红线标注的解码过程我们很显然可以看到一个缺陷：声学模型根据第一个输入，输出了两个标签。例如假设目标标签序列是'hello'，在处理第一个声学输入之后，输出了两个标签<code>h e</code>，显然很多情况下这是不合理的，因此一种对模型增加一种合理的约束，使得模型没解码一个语言模型的状态均需要消耗掉一个声学模型状态，也就是时间步加一。上述问题的根源在于解析过程中计算了从起点到终点所有可能的路径，但是很多路径其实是不合理的，我们需要有一种约束来减少无效空间的搜索。</p>
<p>为了更好的理解RNN-T中的对齐操作，我们使用另外一个<a href="https://zhuanlan.zhihu.com/p/433646030" target="_blank" rel="noopener">例子</a>来讲解。</p>
<img title="" src="https://pic4.zhimg.com/v2-7e00fe462b65f9d6fb52741e37ddbb4f_r.jpg" alt="" width="406" data-align="center">
<p>上图中为语音序列$x=(x_1,x_2,\dots,x_8)$ 和标签序列$y=\text{(<s>, t, e, a, m)}$ 绘制了三个对齐路径示例，其中$<s>$是句子开始的记号。所有有效的对其路径都是从$T\times U$网格左下角到右上角，因此每个对齐路径长度是$T+U$。在对齐路径中，水平箭头通过以空白标签保留预测网络状态并前进一个时间步长，而垂直箭头发出一个非空白输出标签。</p>
<p>虽然RNN-T现在是最自然的端到端流媒体模型，但普通RNN-T仍然面临延迟挑战，因为RNN-T倾向于延迟输出其预测结果，直到通过获得更多未来帧进而产生更高的confidence之后才输出。图4中的绿色路径就是这种延迟决策的示例。为了保证RNN-T的低延迟，有论文提出采用强制对齐的方式，将训练的结果同真实结果之间的对齐强制限制在某一个时间阈值内，并禁止其他对齐路径。输入语音序列和输出标签序列之间的严格对齐，以便为流式RNN-T生成更好的对齐方式。除了延迟的好处之外，所有这些强制对齐RNN-T方法的另一个优点是节省GPU内存和训练加速，因为它们在训练期间使用了较少的对齐路径。</p>
<p>下面将介绍谷歌的RNA模型(Recurrent Neural Aligner)。</p>
<h2 id="recurrent-neural-aligner"><a href="#recurrent-neural-aligner" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Recurrent Neural Aligner</h2>
<p><a href="https://www.isca-speech.org/archive_v0/Interspeech_2017/pdfs/1705.PDF" target="_blank" rel="noopener">论文</a></p>
<p>模型框架如下图：</p>
<img title="" src="https://pic1.zhimg.com/80/v2-b28582bfbedee1dbfc7ef7d5cacce6e0_1440w.jpg" alt="" data-align="center" width="317">
<p>RNA模型使用RNN做为encoder，在decode的时候，有一个假设：输入序列长度大于等于输出序列长度。另外，每个输入对应一个输出（如下图所示），而RNN-T一个输入可能对应多个输出。通过这个限定，RNA的解码搜索空间要小于RNN-T。此外，解码使用了<code>forward-backward algorithm</code>，细节可以参考论文，这里不再展开介绍。</p>
<img title="" src="https://github.com/huangpeng1126/huangpeng1126.github.io/blob/master/images/RNA_001.png?raw=true" alt="" data-align="center" width="397">
<h1 id="neural-transducer"><a href="#neural-transducer" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Neural Transducer</h1>
<h1 id="las"><a href="#las" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>LAS</h1>
<h1 id="mocha"><a href="#mocha" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>MoChA</h1>

            </div>

            
    
    
        <ul class="post-copyright">
            <li class="copyright-item author"><span class="copyright-item-text">作者</span>：<a href="https://huangpeng1126.github.com/" class="p-author h-card" target="_blank" rel="noopener">瞌睡鱼</a></li>
            
                
                
                
                
                <li class="copyright-item link"><span class="copyright-item-text">链接</span>：<a href="/posts/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/" target="_blank" rel="noopener">https://huangpeng1126.github.io/posts/语音识别算法介绍/</a></li>
            
            <li class="copyright-item license"><span class="copyright-item-text">许可</span>：<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a></li>
            
        </ul>
    



        </article>

        

        
    <div class="updated-badge-container">
        <span title="Updated @ 2022-10-08 09:13:27 CST" style="cursor:help">

<svg xmlns="http://www.w3.org/2000/svg" width="130" height="20" class="updated-badge"><linearGradient id="b" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="a"><rect width="130" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#a)"><path class="updated-badge-left" d="M0 0h55v20H0z"/><path class="updated-badge-right" d="M55 0h75v20H55z"/><path fill="url(#b)" d="M0 0h130v20H0z"/></g><g fill="#fff" text-anchor="middle" font-size="110"><text x="285" y="150" fill="#010101" fill-opacity=".3" textLength="450" transform="scale(.1)">updated</text><text x="285" y="140" textLength="450" transform="scale(.1)">updated</text><text x="915" y="150" fill="#010101" fill-opacity=".3" textLength="650" transform="scale(.1)">2022-10-08</text><text x="915" y="140" textLength="650" transform="scale(.1)">2022-10-08</text></g></svg>
        </span></div>



        


        <div class="post-share">

        

        <div class="share-items">

            
                <div class="share-item twitter">
                    
                    <a href="https://twitter.com/share?url=https://huangpeng1126.github.io/posts/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/&amp;text=%e8%af%ad%e9%9f%b3%e8%af%86%e5%88%ab%e7%ae%97%e6%b3%95%e4%bb%8b%e7%bb%8d&amp;hashtags=&amp;via=reuixiy" title="分享到「Twitter」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon twitter-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a>
                </div>
            

            
                <div class="share-item facebook">
                    
                    <a href="https://www.facebook.com/sharer/sharer.php?u=https://huangpeng1126.github.io/posts/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/&amp;hashtag=%23" title="分享到「Facebook」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon facebook-icon"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg></a>
                </div>
            

            
                <div class="share-item linkedin">
                    
                    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://huangpeng1126.github.io/posts/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/&amp;title=%e8%af%ad%e9%9f%b3%e8%af%86%e5%88%ab%e7%ae%97%e6%b3%95%e4%bb%8b%e7%bb%8d&amp;summary=%e8%af%ad%e9%9f%b3%e8%af%86%e5%88%ab%e6%98%af%e4%b8%80%e4%b8%aa%e5%85%b7%e6%9c%89%e6%82%a0%e4%b9%85%e5%8e%86%e5%8f%b2%e7%9a%84%e7%a0%94%e7%a9%b6%e9%a2%86%e5%9f%9f%ef%bc%8c%e4%bb%8e%e4%b9%8b%e5%89%8d%e4%bc%a0%e7%bb%9f%e7%9a%84%e7%bb%9f%e8%ae%a1%e6%a8%a1%e5%9e%8b%ef%bc%8c%e5%88%b0%e7%9b%ae%e5%89%8d%e7%83%ad%e5%ba%a6%e5%be%88%e9%ab%98%e7%9a%84E2E%e6%a1%86%e2%80%a6%e2%80%a6&amp;source=%e7%9e%8c%e7%9d%a1%e9%b1%bc&amp;%e8%8a%b1%e8%84%b8%e7%8c%ab%20%e4%b8%aa%e4%ba%ba%e7%bd%91%e7%ab%99" title="分享到「LinkedIn」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon linkedin-icon"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a>
                </div>
            

            
                <div class="share-item telegram">
                    
                    <a href="https://t.me/share/url?url=https://huangpeng1126.github.io/posts/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/&amp;text=%e8%af%ad%e9%9f%b3%e8%af%86%e5%88%ab%e7%ae%97%e6%b3%95%e4%bb%8b%e7%bb%8d" title="分享到「Telegram」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon telegram-icon"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm121.8 169.9l-40.7 191.8c-3 13.6-11.1 16.9-22.4 10.5l-62-45.7-29.9 28.8c-3.3 3.3-6.1 6.1-12.5 6.1l4.4-63.1 114.9-103.8c5-4.4-1.1-6.9-7.7-2.5l-142 89.4-61.2-19.1c-13.3-4.2-13.6-13.3 2.8-19.7l239.1-92.2c11.1-4 20.8 2.7 17.2 19.5z"/></svg></a>
                </div>
            

            
                <div class="share-item weibo">
                    
                    <a href="https://service.weibo.com/share/share.php?&amp;url=https://huangpeng1126.github.io/posts/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/&amp;title=%e8%af%ad%e9%9f%b3%e8%af%86%e5%88%ab%e7%ae%97%e6%b3%95%e4%bb%8b%e7%bb%8d&amp;pic=https://distill.pub/2017/ctc/assets/cost_no_skip.svg&amp;searchPic=false" title="分享到「新浪微博」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon weibo-icon"><path d="M407 177.6c7.6-24-13.4-46.8-37.4-41.7-22 4.8-28.8-28.1-7.1-32.8 50.1-10.9 92.3 37.1 76.5 84.8-6.8 21.2-38.8 10.8-32-10.3zM214.8 446.7C108.5 446.7 0 395.3 0 310.4c0-44.3 28-95.4 76.3-143.7C176 67 279.5 65.8 249.9 161c-4 13.1 12.3 5.7 12.3 6 79.5-33.6 140.5-16.8 114 51.4-3.7 9.4 1.1 10.9 8.3 13.1 135.7 42.3 34.8 215.2-169.7 215.2zm143.7-146.3c-5.4-55.7-78.5-94-163.4-85.7-84.8 8.6-148.8 60.3-143.4 116s78.5 94 163.4 85.7c84.8-8.6 148.8-60.3 143.4-116zM347.9 35.1c-25.9 5.6-16.8 43.7 8.3 38.3 72.3-15.2 134.8 52.8 111.7 124-7.4 24.2 29.1 37 37.4 12 31.9-99.8-55.1-195.9-157.4-174.3zm-78.5 311c-17.1 38.8-66.8 60-109.1 46.3-40.8-13.1-58-53.4-40.3-89.7 17.7-35.4 63.1-55.4 103.4-45.1 42 10.8 63.1 50.2 46 88.5zm-86.3-30c-12.9-5.4-30 .3-38 12.9-8.3 12.9-4.3 28 8.6 34 13.1 6 30.8.3 39.1-12.9 8-13.1 3.7-28.3-9.7-34zm32.6-13.4c-5.1-1.7-11.4.6-14.3 5.4-2.9 5.1-1.4 10.6 3.7 12.9 5.1 2 11.7-.3 14.6-5.4 2.8-5.2 1.1-10.9-4-12.9z"/></svg></a>
                </div>
            

            
                <div class="share-item douban">
                    
                    <a href="https://www.douban.com/share/service?href=https://huangpeng1126.github.io/posts/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/&amp;name=%e8%af%ad%e9%9f%b3%e8%af%86%e5%88%ab%e7%ae%97%e6%b3%95%e4%bb%8b%e7%bb%8d&amp;text=%e8%af%ad%e9%9f%b3%e8%af%86%e5%88%ab%e6%98%af%e4%b8%80%e4%b8%aa%e5%85%b7%e6%9c%89%e6%82%a0%e4%b9%85%e5%8e%86%e5%8f%b2%e7%9a%84%e7%a0%94%e7%a9%b6%e9%a2%86%e5%9f%9f%ef%bc%8c%e4%bb%8e%e4%b9%8b%e5%89%8d%e4%bc%a0%e7%bb%9f%e7%9a%84%e7%bb%9f%e8%ae%a1%e6%a8%a1%e5%9e%8b%ef%bc%8c%e5%88%b0%e7%9b%ae%e5%89%8d%e7%83%ad%e5%ba%a6%e5%be%88%e9%ab%98%e7%9a%84E2E%e6%a1%86%e2%80%a6%e2%80%a6" title="分享到「豆瓣」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon douban-icon"><path d="M.643.92v2.412h22.714V.92H.643zm1.974 4.926v9.42h18.764v-9.42H2.617zm2.72 2.408H18.69v4.605H5.338V8.254zm1.657 7.412l-2.512.938c1.037 1.461 1.87 2.825 2.512 4.091H0v2.385h24v-2.385h-6.678c.818-1.176 1.589-2.543 2.303-4.091l-2.73-.938a29.952 29.952 0 01-2.479 5.03h-4.75c-.786-1.962-1.677-3.641-2.672-5.03Z"/></svg></a>
                </div>
            

            
                <div class="share-item qq">
                    
                    <a href="https://connect.qq.com/widget/shareqq/index.html?url=https://huangpeng1126.github.io/posts/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/&amp;title=%e8%af%ad%e9%9f%b3%e8%af%86%e5%88%ab%e7%ae%97%e6%b3%95%e4%bb%8b%e7%bb%8d&amp;summary=%e8%af%ad%e9%9f%b3%e8%af%86%e5%88%ab%e6%98%af%e4%b8%80%e4%b8%aa%e5%85%b7%e6%9c%89%e6%82%a0%e4%b9%85%e5%8e%86%e5%8f%b2%e7%9a%84%e7%a0%94%e7%a9%b6%e9%a2%86%e5%9f%9f%ef%bc%8c%e4%bb%8e%e4%b9%8b%e5%89%8d%e4%bc%a0%e7%bb%9f%e7%9a%84%e7%bb%9f%e8%ae%a1%e6%a8%a1%e5%9e%8b%ef%bc%8c%e5%88%b0%e7%9b%ae%e5%89%8d%e7%83%ad%e5%ba%a6%e5%be%88%e9%ab%98%e7%9a%84E2E%e6%a1%86%e2%80%a6%e2%80%a6&amp;pics=https://distill.pub/2017/ctc/assets/cost_no_skip.svg&amp;site=%e7%9e%8c%e7%9d%a1%e9%b1%bc&amp;%e8%8a%b1%e8%84%b8%e7%8c%ab%20%e4%b8%aa%e4%ba%ba%e7%bd%91%e7%ab%99" title="分享到「QQ」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon qq-icon"><path d="M433.754 420.445c-11.526 1.393-44.86-52.741-44.86-52.741 0 31.345-16.136 72.247-51.051 101.786 16.842 5.192 54.843 19.167 45.803 34.421-7.316 12.343-125.51 7.881-159.632 4.037-34.122 3.844-152.316 8.306-159.632-4.037-9.045-15.25 28.918-29.214 45.783-34.415-34.92-29.539-51.059-70.445-51.059-101.792 0 0-33.334 54.134-44.859 52.741-5.37-.65-12.424-29.644 9.347-99.704 10.261-33.024 21.995-60.478 40.144-105.779C60.683 98.063 108.982.006 224 0c113.737.006 163.156 96.133 160.264 214.963 18.118 45.223 29.912 72.85 40.144 105.778 21.768 70.06 14.716 99.053 9.346 99.704z"/></svg></a>
                </div>
            

            
                <div class="share-item qzone">
                    
                    <a href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://huangpeng1126.github.io/posts/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/&amp;title=%e8%af%ad%e9%9f%b3%e8%af%86%e5%88%ab%e7%ae%97%e6%b3%95%e4%bb%8b%e7%bb%8d&amp;summary=%e8%af%ad%e9%9f%b3%e8%af%86%e5%88%ab%e6%98%af%e4%b8%80%e4%b8%aa%e5%85%b7%e6%9c%89%e6%82%a0%e4%b9%85%e5%8e%86%e5%8f%b2%e7%9a%84%e7%a0%94%e7%a9%b6%e9%a2%86%e5%9f%9f%ef%bc%8c%e4%bb%8e%e4%b9%8b%e5%89%8d%e4%bc%a0%e7%bb%9f%e7%9a%84%e7%bb%9f%e8%ae%a1%e6%a8%a1%e5%9e%8b%ef%bc%8c%e5%88%b0%e7%9b%ae%e5%89%8d%e7%83%ad%e5%ba%a6%e5%be%88%e9%ab%98%e7%9a%84E2E%e6%a1%86%e2%80%a6%e2%80%a6&amp;pics=https://distill.pub/2017/ctc/assets/cost_no_skip.svg&amp;site=%e7%9e%8c%e7%9d%a1%e9%b1%bc&amp;%e8%8a%b1%e8%84%b8%e7%8c%ab%20%e4%b8%aa%e4%ba%ba%e7%bd%91%e7%ab%99" title="分享到「QQ 空间」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon qzone-icon"><path d="M23.985 9.202c-.032-.099-.127-.223-.334-.258-.207-.036-7.351-1.406-7.351-1.406s-.105-.022-.198-.07c-.092-.047-.127-.167-.127-.167S12.447.956 12.349.77C12.25.583 12.104.532 12 .532c-.104 0-.251.051-.349.238-.098.186-3.626 6.531-3.626 6.531s-.035.12-.128.167c-.092.047-.197.07-.197.07S.556 8.908.348 8.943c-.208.036-.302.16-.333.258a.477.477 0 0 0 .125.449l5.362 5.49s.072.08.119.172c.016.104.005.21.005.21s-1.189 7.242-1.22 7.45.075.369.159.43c.083.062.233.106.421.013.189-.093 6.812-3.261 6.812-3.261s.098-.044.201-.061c.103-.017.201.061.201.061s6.623 3.168 6.812 3.261c.188.094.338.049.421-.013a.463.463 0 0 0 .159-.43c-.021-.14-.93-5.677-.93-5.677.876-.54 1.425-1.039 1.849-1.747-2.594.969-6.006 1.717-9.415 1.866-.915.041-2.41.097-3.473-.015-.678-.071-1.17-.144-1.243-.438-.053-.215.054-.46.545-.831a2640.5 2640.5 0 0 1 2.861-2.155c1.285-.968 3.559-2.47 3.559-2.731 0-.285-2.144-.781-4.037-.781-1.945 0-2.275.132-2.811.168-.488.034-.769.005-.804-.138-.06-.248.183-.389.588-.568.709-.314 1.86-.594 1.984-.626.194-.052 3.082-.805 5.618-.535 1.318.14 3.244.668 3.244 1.276 0 .342-1.721 1.494-3.225 2.597-1.149.843-2.217 1.561-2.217 1.688 0 .342 3.533 1.241 6.689 1.01l.003-.022c.048-.092.119-.172.119-.172l5.362-5.49a.477.477 0 0 0 .127-.449z"/></svg></a>
                </div>
            

            
                <div class="share-item qrcode">
                    <div class="qrcode-container" title="通过「二维码」"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon qrcode-icon"><path d="M0 224h192V32H0v192zM64 96h64v64H64V96zm192-64v192h192V32H256zm128 128h-64V96h64v64zM0 480h192V288H0v192zm64-128h64v64H64v-64zm352-64h32v128h-96v-32h-32v96h-64V288h96v32h64v-32zm0 160h32v32h-32v-32zm-64 0h32v32h-32v-32z"/></svg><div id="qrcode-img"></div>
                    </div>
                    <script src="https://cdn.jsdelivr.net/npm/qrcode-generator@1.4.4/qrcode.min.js"></script>

<script>
    var typeNumber = 0;
    var errorCorrectionLevel = 'L';
    var qr = qrcode(typeNumber, errorCorrectionLevel);
    qr.addData('https:\/\/huangpeng1126.github.io\/posts\/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D\/');
    qr.make();
    document.getElementById('qrcode-img').innerHTML = qr.createImgTag();
</script>

                </div>
            

        </div>

    </div>




        
    
    



        
    



        


        


        
    
        
        
    
    
    
    
        <ul class="post-nav">
            
                <li class="post-nav-prev">
                    <a href="/posts/crf_memm_hmm/" rel="prev">&lt; CRF_MEMM_HMM</a>
                </li>
            
            
                <li class="post-nav-next">
                    <a href="/posts/%E5%B8%B8%E8%A7%81%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%BB%8B%E7%BB%8D/" rel="next">常见损失函数介绍 &gt;</a>
                </li>
            
        </ul>
    



        


    </div>
</main>


            
    <div id="back-to-top" class="back-to-top">
        <a href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon arrow-up"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6 0-33.9L207 39c9.4-9.4 24.6-9.4 33.9 0l194.3 194.3c9.4 9.4 9.4 24.6 0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3 0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg></a>
    </div>


            
    <footer id="footer" class="footer">
        <div class="footer-inner">
            <div class="site-info">©&nbsp;1969–2022&nbsp;<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon footer-icon"><path d="M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z"/></svg>&nbsp;瞌睡鱼</div><div class="powered-by">Powered by <a href="https://github.com/gohugoio/hugo" target="_blank" rel="noopener">Hugo</a> | Theme is <a href="https://github.com/reuixiy/hugo-theme-meme" target="_blank" rel="noopener">MemE</a></div><div class="site-copyright"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a></div>

            
    
        <ul class="socials"><li class="socials-item">
                    <a href="/rss.xml" target="_blank" rel="external noopener" title="RSS"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon social-icon"><path d="M19.199 24C19.199 13.467 10.533 4.8 0 4.8V0c13.165 0 24 10.835 24 24h-4.801zM3.291 17.415c1.814 0 3.293 1.479 3.293 3.295 0 1.813-1.485 3.29-3.301 3.29C1.47 24 0 22.526 0 20.71s1.475-3.294 3.291-3.295zM15.909 24h-4.665c0-6.169-5.075-11.245-11.244-11.245V8.09c8.727 0 15.909 7.184 15.909 15.91z"/></svg></a>
                </li><li class="socials-item">
                    <a href="mailto:reuixiy@gmail.com" target="_blank" rel="external noopener" title="Email"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon social-icon"><path d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://github.com/reuixiy" target="_blank" rel="external noopener" title="GitHub"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon social-icon"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://twitter.com/reuixiy" target="_blank" rel="external noopener" title="Twitter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon social-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://t.me/yixiuer" target="_blank" rel="external noopener" title="Telegram"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon social-icon"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm121.8 169.9l-40.7 191.8c-3 13.6-11.1 16.9-22.4 10.5l-62-45.7-29.9 28.8c-3.3 3.3-6.1 6.1-12.5 6.1l4.4-63.1 114.9-103.8c5-4.4-1.1-6.9-7.7-2.5l-142 89.4-61.2-19.1c-13.3-4.2-13.6-13.3 2.8-19.7l239.1-92.2c11.1-4 20.8 2.7 17.2 19.5z"/></svg></a>
                </li></ul>
    



            
        </div>
    </footer>


        </div>
        

        
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css" integrity="sha256-gPJfuwTULrEAAcI3X4bALVU/2qBU+QY/TpoD3GO+Exw=" crossorigin="anonymous">
<script>
    if (typeof renderMathInElement === 'undefined') {
        var getScript = (options) => {
            var script = document.createElement('script');
            script.defer = true;
            script.crossOrigin = 'anonymous';
            Object.keys(options).forEach((key) => {
                script[key] = options[key];
            });
            document.body.appendChild(script);
        };
        getScript({
            src: 'https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js',
            integrity: 'sha256-YTW9cMncW/ZQMhY69KaUxIa2cPTxV87Uh627Gf5ODUw=',
            onload: () => {
                getScript({
                    src: 'https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/mhchem.min.js',
                    integrity: 'sha256-yzSfYeVsWJ1x+2g8CYHsB/Mn7PcSp8122k5BM4T3Vxw=',
                    onload: () => {
                        getScript({
                            src: 'https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/auto-render.min.js',
                            integrity: 'sha256-fxJzNV6hpc8tgW8tF0zVobKa71eTCRGTgxFXt1ZpJNM=',
                            onload: () => {
                                renderKaTex();
                            }
                        });
                    }
                });
            }
        });
    } else {
        renderKaTex();
    }
    function renderKaTex() {
        renderMathInElement(
            document.body,
            {
                delimiters: [
                    {left: "$$", right: "$$", display: true},
                    {left: "\\[", right: "\\]", display: true},
                    {left: "$", right: "$", display: false},
                    {left: "\\(", right: "\\)", display: false}
                ]
            }
        );
    }
</script>




    <script>
    if (typeof MathJax === 'undefined') {
        window.MathJax = {
            loader: {
                load: ['[tex]/mhchem']
            },
            
            tex: {
                inlineMath: {'[+]': [['$', '$']]},
                tags: 'ams',
                packages: {'[+]': ['mhchem']}
            }
        };
        (function() {
            var script = document.createElement('script');
            script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
            script.defer = true;
            document.head.appendChild(script);
        })();
    } else {
        MathJax.texReset();
        MathJax.typeset();
    }
</script>




    <script src="https://cdn.jsdelivr.net/npm/mermaid@8.8.3/dist/mermaid.min.js"></script>
<script>
    let mermaidConfig = {
        startOnLoad: true,
        flowchart: {
            useMaxWidth: false,
            htmlLabels: true
        },
        theme: 'default'
    };
    mermaid.initialize(mermaidConfig);
</script>





    <script src="https://cdn.jsdelivr.net/npm/medium-zoom@latest/dist/medium-zoom.min.js"></script>

<script>
    let imgNodes = document.querySelectorAll('div.post-body img');
    imgNodes = Array.from(imgNodes).filter(node => node.parentNode.tagName !== "A");

    mediumZoom(imgNodes, {
        background: 'hsla(var(--color-bg-h), var(--color-bg-s), var(--color-bg-l), 0.95)'
    })
</script>




    <script src="https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js" type="module" defer></script>







    </body>
</html>
